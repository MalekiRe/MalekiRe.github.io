<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <title>Bevy game</title> <!-- ToDo -->
    
    
    <link rel="icon" href="icon.ico">
    <style nonce="A84RaGmk5SYLE1o9Yhb1fA==">.game-container {
    display: flex;
    justify-content: center;
    align-items: center;
}

#bevy {
    z-index: 2;
}
</style>

<link rel="modulepreload" href="./p2pvr-6a003f856ba25989.js" crossorigin=anonymous integrity="sha384-0THqWiAFWdV9LHnfoTGhCbTJGE0Qz74kWGhloWdU3yTOkhM90oxmjgAOgwzvnhMI">
<link rel="preload" href="./p2pvr-6a003f856ba25989_bg.wasm" crossorigin=anonymous integrity="sha384-l+SsXdUANwUCREAEBe+M09euAkhzOgY7sVo2z8UvBziRYy/Gmg0zOxh+RuTgNbxC" as="fetch" type="application/wasm"></head>
<body>
    <canvas id="bevy">
        Javascript and support for canvas is required
    </canvas>
<script nonce="vXSrxKgSPXL+sYuYb1lrug==">// Insert hack to make sound autoplay on Chrome as soon as the user interacts with the tab:
// https://developers.google.com/web/updates/2018/11/web-audio-autoplay#moving-forward

// the following function keeps track of all AudioContexts and resumes them on the first user
// interaction with the page. If the function is called and all contexts are already running,
// it will remove itself from all event listeners.
(function () {
    // An array of all contexts to resume on the page
    const audioContextList = [];

    // An array of various user interaction events we should listen for
    const userInputEventNames = [
        "click",
        "contextmenu",
        "auxclick",
        "dblclick",
        "mousedown",
        "mouseup",
        "pointerup",
        "touchend",
        "keydown",
        "keyup",
    ];

    // A proxy object to intercept AudioContexts and
    // add them to the array for tracking and resuming later
    self.AudioContext = new Proxy(self.AudioContext, {
        construct(target, args) {
            const result = new target(...args);
            audioContextList.push(result);
            return result;
        },
    });

    // To resume all AudioContexts being tracked
    function resumeAllContexts(_event) {
        let count = 0;

        audioContextList.forEach((context) => {
            if (context.state !== "running") {
                context.resume();
            } else {
                count++;
            }
        });

        // If all the AudioContexts have now resumed then we unbind all
        // the event listeners from the page to prevent unnecessary resume attempts
        // Checking count > 0 ensures that the user interaction happens AFTER the game started up
        if (count > 0 && count === audioContextList.length) {
            userInputEventNames.forEach((eventName) => {
                document.removeEventListener(eventName, resumeAllContexts);
            });
        }
    }

    // We bind the resume function for each user interaction
    // event on the page
    userInputEventNames.forEach((eventName) => {
        document.addEventListener(eventName, resumeAllContexts);
    });
})();
</script>

<script type="module" nonce="20xovokCqPpMGpGs4ZqUow==">
import init, * as bindings from './p2pvr-6a003f856ba25989.js';
const wasm = await init('./p2pvr-6a003f856ba25989_bg.wasm');


window.wasmBindings = bindings;


dispatchEvent(new CustomEvent("TrunkApplicationStarted", {detail: {wasm}}));

</script></body>
</html>